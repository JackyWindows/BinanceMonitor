import requests
import pandas as pd
from datetime import datetime, timedelta
import time
import concurrent.futures
import json
import streamlit as st
import plotly.graph_objects as go
import os

# Binance API ç«¯ç‚¹
SPOT_BASE_URL = "https://api.binance.com/api/v3"
FUTURES_BASE_URL = "https://fapi.binance.com/fapi/v1"

# DeepSeek API é…ç½®ï¼ˆå‡è®¾ä½¿ç”¨å®˜æ–¹APIï¼Œéœ€æ›¿æ¢ä¸ºä½ çš„API Keyï¼‰
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
DEEPSEEK_API_KEY = "sk-678e106a83314b3fb2db62689c224399"  # è¯·æ›¿æ¢ä¸ºå®é™…çš„API Key

# ç¨³å®šå¸åˆ—è¡¨ï¼ˆç¾å…ƒç¨³å®šå¸å’Œæ¬§å…ƒç¨³å®šå¸ï¼‰
STABLECOINS = {'USDC', 'TUSD', 'BUSD', 'DAI', 'USDP', 'EUR', 'GYEN'}

def get_all_usdt_symbols(is_futures=False):
    """è·å–æ‰€æœ‰ä»¥USDTç»“å°¾çš„äº¤æ˜“å¯¹ï¼Œå‰”é™¤ç¨³å®šå¸å¯¹"""
    base_url = FUTURES_BASE_URL if is_futures else SPOT_BASE_URL
    endpoint = "/exchangeInfo"

    response = requests.get(f"{base_url}{endpoint}")
    data = response.json()

    symbols = []
    if is_futures:
        for item in data['symbols']:
            symbol = item['symbol']
            base_asset = item['baseAsset']
            if (item['status'] == 'TRADING' and
                item['quoteAsset'] == 'USDT' and
                base_asset not in STABLECOINS):
                symbols.append(symbol)
    else:
        for item in data['symbols']:
            symbol = item['symbol']
            base_asset = item['baseAsset']
            if (item['status'] == 'TRADING' and
                item['quoteAsset'] == 'USDT' and
                base_asset not in STABLECOINS):
                symbols.append(symbol)
    return symbols

def format_number(value):
    """å°†æ•°å€¼æ ¼å¼åŒ–ä¸ºK/Mè¡¨ç¤ºï¼Œä¿ç•™ä¸¤ä½å°æ•°"""
    if abs(value) >= 1000000:
        return f"{value / 1000000:.2f}M"
    elif abs(value) >= 1000:
        return f"{value / 1000:.2f}K"
    else:
        return f"{value:.2f}"

def get_klines_parallel(symbols, is_futures=False, max_workers=20):
    """ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–å¤šä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®ï¼ˆä½¿ç”¨å€’æ•°ç¬¬äºŒæ ¹å·²å®Œæˆçš„æ—¥çº¿èœ¡çƒ›å›¾ï¼‰"""
    results = []

    def fetch_kline(symbol):
        try:
            base_url = FUTURES_BASE_URL if is_futures else SPOT_BASE_URL
            endpoint = "/klines"

            now = datetime.utcnow()
            today_start = datetime(now.year, now.month, now.day, 0, 0, 0)
            end_time = int(today_start.timestamp() * 1000)
            start_time = int((today_start - timedelta(days=2)).timestamp() * 1000)

            params = {
                'symbol': symbol,
                'interval': '4h',
                'startTime': start_time,
                'endTime': end_time,
                'limit': 2
            }

            response = requests.get(f"{base_url}{endpoint}", params=params)
            data = response.json()

            if not data or len(data) < 2:
                print(f"Insufficient data for {symbol}: {len(data)} candles returned")
                return None

            k = data[1]  # ä½¿ç”¨å€’æ•°ç¬¬ä¸€æ ¹å·²å®ŒæˆKçº¿
            open_time = datetime.fromtimestamp(k[0] / 1000).strftime('%Y-%m-%d %H:%M:%S')
            close_time = datetime.fromtimestamp(k[6] / 1000).strftime('%Y-%m-%d %H:%M:%S')

            return {
                'symbol': symbol,
                'open_time': open_time,
                'close_time': close_time,
                'open': float(k[1]),
                'high': float(k[2]),
                'low': float(k[3]),
                'close': float(k[4]),
                'volume': float(k[5]),
                'quote_volume': float(k[7]),
                'trades': int(k[8]),
                'taker_buy_base_volume': float(k[9]),
                'taker_buy_quote_volume': float(k[10]),
                'net_inflow': 2 * float(k[10]) - float(k[7])
            }
        except Exception as e:
            print(f"Error fetching {symbol}: {e}")
            return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(fetch_kline, symbol): symbol for symbol in symbols}
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if result:
                results.append(result)

    return results

def send_to_deepseek(data):
    """å°†æ•°æ®å‘é€ç»™DeepSeek APIå¹¶è·å–è§£è¯»"""
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }

    prompt = (
        "ä»¥ä¸‹æ˜¯Binanceç°è´§å’ŒæœŸè´§å¸‚åœºä¸­USDTäº¤æ˜“å¯¹çš„èµ„é‡‘æµå…¥æµå‡ºæ•°æ®ï¼ˆåŸºäºå‰ä¸€å¤©çš„å·²å®Œæˆæ—¥çº¿æ•°æ®ï¼‰ï¼Œè¯·åˆ†æï¼š\n"
        "1. æœŸè´§å’Œç°è´§å¸‚åœºä¸­å‡ºç°çš„ç›¸åŒäº¤æ˜“å¯¹åŠå…¶æµå…¥æµå‡ºæƒ…å†µã€‚\n"
        "2. ä»èµ„é‡‘æµè§’åº¦è§£è¯»è¿™äº›æ•°æ®ï¼Œå¯èƒ½çš„å¸‚åœºè¶‹åŠ¿æˆ–äº¤æ˜“ä¿¡å·ã€‚\n"
        "3. æä¾›ä¸“ä¸šçš„èµ„é‡‘åˆ†æè§†è§’ï¼Œä¾‹å¦‚å¤§èµ„é‡‘åŠ¨å‘ã€æ½œåœ¨çš„å¸‚åœºæ“çºµè¿¹è±¡ç­‰ã€‚\n"
        "æ•°æ®å¦‚ä¸‹ï¼š\n" + json.dumps(data, indent=2, ensure_ascii=False) +
        "\nè¯·ä»¥ä¸­æ–‡å›å¤ï¼Œå°½é‡ç®€æ´ä½†ä¸“ä¸šã€‚"
    )

    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 1000,
        "temperature": 0.7
    }

    try:
        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()
        return result['choices'][0]['message']['content']
    except Exception as e:
        print(f"DeepSeek API error: {e}")
        return "æ— æ³•è·å–DeepSeekåˆ†æç»“æœ"

def run_analysis():
    """æ‰§è¡Œåˆ†æå¹¶è¿”å›ç»“æœ"""
    # è·å–æ‰€æœ‰USDTäº¤æ˜“å¯¹ï¼ˆå‰”é™¤ç¨³å®šå¸ï¼‰
    spot_symbols = get_all_usdt_symbols(is_futures=False)
    futures_symbols = get_all_usdt_symbols(is_futures=True)

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–æ•°æ®
    spot_data = get_klines_parallel(spot_symbols, is_futures=False, max_workers=20)
    futures_data = get_klines_parallel(futures_symbols, is_futures=True, max_workers=20)

    # è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
    spot_df = pd.DataFrame(spot_data)
    futures_df = pd.DataFrame(futures_data)

    # æå–Top 20æ•°æ®
    spot_inflow_top20 = spot_df.sort_values(by='net_inflow', ascending=False).head(20)
    futures_inflow_top20 = futures_df.sort_values(by='net_inflow', ascending=False).head(20)
    spot_outflow_top20 = spot_df.sort_values(by='net_inflow', ascending=True).head(20)
    futures_outflow_top20 = futures_df.sort_values(by='net_inflow', ascending=True).head(20)

    # å‡†å¤‡å‘é€ç»™DeepSeekçš„æ•°æ®
    deepseek_data = {
        "spot_inflow_top20": spot_inflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records'),
        "futures_inflow_top20": futures_inflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records'),
        "spot_outflow_top20": spot_outflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records'),
        "futures_outflow_top20": futures_outflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records')
    }

    # å‘é€ç»™DeepSeekå¹¶è·å–åˆ†æ
    analysis = send_to_deepseek(deepseek_data)
    
    # è¿”å›æ‰€æœ‰ç»“æœ
    return {
        "spot_inflow_top20": spot_inflow_top20,
        "futures_inflow_top20": futures_inflow_top20,
        "spot_outflow_top20": spot_outflow_top20,
        "futures_outflow_top20": futures_outflow_top20,
        "analysis": analysis,
        "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }

def main():
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="èµ„é‡‘æµå‘åˆ†æ",
        page_icon="ğŸ’°",
        layout="wide"
    )
    
    st.title("ğŸ’° èµ„é‡‘æµå‘åˆ†æ")
    st.markdown("åˆ†æå¸å®‰ç°è´§å’ŒæœŸè´§å¸‚åœºçš„èµ„é‡‘æµå‘ï¼Œè¯†åˆ«æ½œåœ¨äº¤æ˜“æœºä¼š")
    
    # æ·»åŠ åˆ·æ–°æŒ‰é’®
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
        with st.spinner("æ­£åœ¨è·å–æœ€æ–°æ•°æ®..."):
            results = run_analysis()
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            with open("money_flow_analysis.json", "w") as f:
                json.dump({
                    "spot_inflow_top20": results["spot_inflow_top20"].to_dict('records'),
                    "futures_inflow_top20": results["futures_inflow_top20"].to_dict('records'),
                    "spot_outflow_top20": results["spot_outflow_top20"].to_dict('records'),
                    "futures_outflow_top20": results["futures_outflow_top20"].to_dict('records'),
                    "analysis": results["analysis"],
                    "timestamp": results["timestamp"]
                }, f, indent=4, ensure_ascii=False)
            
            st.success("æ•°æ®å·²æ›´æ–°!")
            st.rerun()
    
    # æ·»åŠ è‡ªåŠ¨åˆ·æ–°é€‰é¡¹
    auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (æ¯5åˆ†é’Ÿ)", value=True)
    
    # è¯»å–å¹¶æ˜¾ç¤ºç»Ÿè®¡æ•°æ®
    try:
        if os.path.exists("money_flow_analysis.json"):
            with open("money_flow_analysis.json", "r") as f:
                data = json.load(f)
                
                # æ˜¾ç¤ºæœ€åæ›´æ–°æ—¶é—´
                timestamp = data.get("timestamp", "æœªçŸ¥")
                st.caption(f"æœ€åæ›´æ–°æ—¶é—´: {timestamp}")
                
                # æ˜¾ç¤ºDeepSeekåˆ†æç»“æœ
                st.subheader("ğŸ¤– DeepSeek åˆ†æ")
                st.markdown(data.get("analysis", "æš‚æ— åˆ†æç»“æœ"))
                
                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸŸ¢ ç°è´§å¸‚åœºå‡€æµå…¥TOP20")
                    if "spot_inflow_top20" in data and data["spot_inflow_top20"]:
                        df_spot_inflow = pd.DataFrame([
                            {"äº¤æ˜“å¯¹": item.get("symbol", ""),
                             "å‡€æµå…¥": f"{format_number(item.get('net_inflow', 0))} USDT",
                             "æˆäº¤é¢": f"{format_number(item.get('quote_volume', 0))} USDT"}
                            for item in data["spot_inflow_top20"]
                        ])
                        st.dataframe(df_spot_inflow, hide_index=True)
                        
                        
                    else:
                        st.write("æš‚æ— æ•°æ®")
                
                with col2:
                    st.subheader("ğŸ”´ ç°è´§å¸‚åœºå‡€æµå‡ºTOP20")
                    if "spot_outflow_top20" in data and data["spot_outflow_top20"]:
                        df_spot_outflow = pd.DataFrame([
                            {"äº¤æ˜“å¯¹": item.get("symbol", ""),
                             "å‡€æµå‡º": f"{format_number(item.get('net_inflow', 0))} USDT",
                             "æˆäº¤é¢": f"{format_number(item.get('quote_volume', 0))} USDT"}
                            for item in data["spot_outflow_top20"]
                        ])
                        st.dataframe(df_spot_outflow, hide_index=True)
                        
                        
                    else:
                        st.write("æš‚æ— æ•°æ®")
                
                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€æ˜¾ç¤ºæœŸè´§å¸‚åœºæ•°æ®
                col3, col4 = st.columns(2)
                
                with col3:
                    st.subheader("ğŸŸ¢ æœŸè´§å¸‚åœºå‡€æµå…¥TOP20")
                    if "futures_inflow_top20" in data and data["futures_inflow_top20"]:
                        df_futures_inflow = pd.DataFrame([
                            {"äº¤æ˜“å¯¹": item.get("symbol", ""),
                             "å‡€æµå…¥": f"{format_number(item.get('net_inflow', 0))} USDT",
                             "æˆäº¤é¢": f"{format_number(item.get('quote_volume', 0))} USDT"}
                            for item in data["futures_inflow_top20"]
                        ])
                        st.dataframe(df_futures_inflow, hide_index=True)
                        
                        
                    else:
                        st.write("æš‚æ— æ•°æ®")
                
                with col4:
                    st.subheader("ğŸ”´ æœŸè´§å¸‚åœºå‡€æµå‡ºTOP20")
                    if "futures_outflow_top20" in data and data["futures_outflow_top20"]:
                        df_futures_outflow = pd.DataFrame([
                            {"äº¤æ˜“å¯¹": item.get("symbol", ""),
                             "å‡€æµå‡º": f"{format_number(item.get('net_inflow', 0))} USDT",
                             "æˆäº¤é¢": f"{format_number(item.get('quote_volume', 0))} USDT"}
                            for item in data["futures_outflow_top20"]
                        ])
                        st.dataframe(df_futures_outflow, hide_index=True)
                        
                        
                    else:
                        st.write("æš‚æ— æ•°æ®")
        else:
            st.warning("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æ•°æ®")
            
            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿è¡Œä¸€æ¬¡ä»»åŠ¡
            if st.button("è·å–æ•°æ®"):
                with st.spinner("æ­£åœ¨è·å–æ•°æ®..."):
                    results = run_analysis()
                    
                    # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
                    with open("money_flow_analysis.json", "w") as f:
                        json.dump({
                            "spot_inflow_top20": results["spot_inflow_top20"].to_dict('records'),
                            "futures_inflow_top20": results["futures_inflow_top20"].to_dict('records'),
                            "spot_outflow_top20": results["spot_outflow_top20"].to_dict('records'),
                            "futures_outflow_top20": results["futures_outflow_top20"].to_dict('records'),
                            "analysis": results["analysis"],
                            "timestamp": results["timestamp"]
                        }, f, indent=4, ensure_ascii=False)
                    
                    st.success("æ•°æ®å·²è·å–!")
                    st.rerun()
    
    except Exception as e:
        st.error(f"è¯»å–æ•°æ®æ—¶å‡ºé”™: {e}")
    
    # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨åˆ·æ–°ï¼Œè®¾ç½®å®šæ—¶åˆ·æ–°
    if auto_refresh:
        st.caption("é¡µé¢å°†åœ¨5åˆ†é’Ÿåè‡ªåŠ¨åˆ·æ–°")
        time.sleep(300)  # ç­‰å¾…5åˆ†é’Ÿ
        st.rerun()

if __name__ == "__main__":
    main()
