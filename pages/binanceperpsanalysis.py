import streamlit as st
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
import time
from openai import OpenAI
import logging
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
import threading
from typing import List, Dict
import json
import os
import plotly.graph_objects as go

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¸å®‰æœŸè´§æŒä»“åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main {
        background-color: #0e1117;
    }
    div.stButton > button {
        width: 100%;
        background-color: #FF4B4B;
        color: white;
        border-radius: 10px;
        padding: 0.8rem 1rem;
        font-size: 16px;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    .metric-container {
        background-color: #1E2130;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    .report-container {
        background-color: #1E2130;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    </style>
    """, unsafe_allow_html=True)

# OpenAIé…ç½®
OPENAI_API_KEY = "sk-C9b9fUXzuqQzW7Biq5NdFK0v6BrgicfsjFurqDpz2Ilul6O1"
client = OpenAI(
    api_key=OPENAI_API_KEY,
    base_url="https://api.tu-zi.com/v1"
)


class RateLimiter:
    def __init__(self, max_requests: int, time_window: float):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = Queue()
        self.lock = threading.Lock()

    def acquire(self):
        with self.lock:
            current_time = time.time()
            while not self.requests.empty():
                request_time = self.requests.queue[0]
                if current_time - request_time > self.time_window:
                    self.requests.get()
                else:
                    break
            if self.requests.qsize() >= self.max_requests:
                oldest_request = self.requests.queue[0]
                sleep_time = oldest_request + self.time_window - current_time
                if sleep_time > 0:
                    time.sleep(sleep_time)
            self.requests.put(current_time)


class BinanceFuturesAnalyzer:
    def __init__(self):
        self.base_url = "https://fapi.binance.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.rate_limiter = RateLimiter(max_requests=5, time_window=1.0)

    def make_request(self, url: str, params: dict = None) -> dict:
        self.rate_limiter.acquire()
        response = requests.get(url, params=params, headers=self.headers)
        return response.json()

    def get_usdt_symbols(self) -> List[str]:
        try:
            data = self.make_request(f"{self.base_url}/fapi/v1/exchangeInfo")
            symbols = [item['symbol'] for item in data['symbols']
                       if item['symbol'].endswith('USDT') and item['status'] == 'TRADING']
            return symbols
        except Exception as e:
            st.error(f"è·å–äº¤æ˜“å¯¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []

    def get_position_data(self, symbol: str, historical_timestamp: int) -> Dict:
        try:
            current_data = self.make_request(
                f"{self.base_url}/fapi/v1/openInterest",
                {'symbol': symbol}
            )
            current_oi = float(current_data['openInterest'])

            historical_data = self.make_request(
                f"{self.base_url}/futures/data/openInterestHist",
                {
                    'symbol': symbol,
                    'period': '1h',
                    'limit': 1,
                    'endTime': historical_timestamp
                }
            )
            historical_oi = float(historical_data[0]['sumOpenInterest']) if historical_data else 0

            change = current_oi - historical_oi
            change_percentage = (change / historical_oi * 100) if historical_oi != 0 else 0

            return {
                'symbol': symbol,
                'current_oi': current_oi,
                'historical_oi': historical_oi,
                'change': change,
                'change_percentage': change_percentage
            }
        except Exception as e:
            return {
                'symbol': symbol,
                'current_oi': 0,
                'historical_oi': 0,
                'change': 0,
                'change_percentage': 0
            }

    def analyze_positions(self):
        symbols = self.get_usdt_symbols()
        historical_timestamp = int((datetime.now() - timedelta(hours=4)).timestamp() * 1000)
        results = []

        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_symbol = {
                executor.submit(self.get_position_data, symbol, historical_timestamp): symbol
                for symbol in symbols
            }

            for future in future_to_symbol:
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                except Exception as e:
                    st.error(f"å¤„ç†ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")

        return pd.DataFrame(results)


def get_ai_analysis(df: pd.DataFrame):
    """è·å–AIåˆ†æç»“æœ"""
    try:
        increased = len(df[df['change'] > 0])
        decreased = len(df[df['change'] < 0])

        top_increase = df[df['change'] > 0].sort_values('change_percentage', ascending=False).head(10)
        top_decrease = df[df['change'] < 0].sort_values('change_percentage', ascending=True).head(10)

        prompt = f"""
        ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æœŸè´§äº¤æ˜“åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æŒä»“æ•°æ®å˜åŒ–æä¾›è¯¦ç»†çš„å¸‚åœºåˆ†ææŠ¥å‘Šï¼š

        å¸‚åœºæ¦‚å†µï¼š
        - æ€»äº¤æ˜“å¯¹æ•°é‡ï¼š{len(df)}
        - æŒä»“å¢åŠ æ•°é‡ï¼š{increased}
        - æŒä»“å‡å°‘æ•°é‡ï¼š{decreased}

        æŒä»“å¢åŠ æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹ï¼š
        {top_increase.to_string()}

        æŒä»“å‡å°‘æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹ï¼š
        {top_decrease.to_string()}

        è¯·æä¾›ä»¥ä¸‹åˆ†æï¼ˆä½¿ç”¨markdownæ ¼å¼ï¼‰ï¼š

        ## å¸‚åœºæƒ…ç»ªåˆ†æ
        [åˆ†ææ•´ä½“å¸‚åœºæƒ…ç»ª]

        ## ä¸»è¦å˜åŠ¨è§£è¯»
        - å¤§é¢æŒä»“å¢åŠ åˆ†æï¼š
        - å¤§é¢æŒä»“å‡å°‘åˆ†æï¼š
        - æ½œåœ¨å¸‚åœºæ–¹å‘ï¼š

        ## äº¤æ˜“æœºä¼šåˆ†æ
        - é«˜å…³æ³¨åº¦å“ç§ï¼š
        - æ½œåœ¨è¶‹åŠ¿æœºä¼šï¼š
        - é£é™©æç¤ºï¼š

        è¯·ä»ä¸“ä¸šäº¤æ˜“å‘˜çš„è§’åº¦è¿›è¡Œåˆ†æï¼Œæ³¨é‡å®ç”¨æ€§å’Œæ“ä½œæ€§ã€‚
        """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AI åˆ†æç”Ÿæˆå¤±è´¥: {str(e)}"

def main():
    st.title("ğŸ“Š å¸å®‰æœŸè´§æŒä»“åˆ†æç³»ç»Ÿ")
    st.markdown("åˆ†æå¸å®‰æœŸè´§å¸‚åœºçš„æŒä»“å˜åŒ–ï¼Œè¯†åˆ«æ½œåœ¨äº¤æ˜“æœºä¼š")
    
    # æ·»åŠ åˆ·æ–°æŒ‰é’®
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
        with st.spinner("æ­£åœ¨è·å–æœ€æ–°æ•°æ®..."):
            analyzer = BinanceFuturesAnalyzer()
            df = analyzer.analyze_positions()
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            with open("binance_perps_analysis.json", "w") as f:
                json.dump({
                    "data": df.to_dict('records'),
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }, f, indent=4, ensure_ascii=False)
            
            st.success("æ•°æ®å·²æ›´æ–°!")
            st.rerun()
    
    # æ·»åŠ è‡ªåŠ¨åˆ·æ–°é€‰é¡¹
    auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (æ¯5åˆ†é’Ÿ)", value=True)
    
    # è¯»å–å¹¶æ˜¾ç¤ºç»Ÿè®¡æ•°æ®
    try:
        if os.path.exists("binance_perps_analysis.json"):
            with open("binance_perps_analysis.json", "r") as f:
                data = json.load(f)
                
                # æ˜¾ç¤ºæœ€åæ›´æ–°æ—¶é—´
                timestamp = data.get("timestamp", "æœªçŸ¥")
                st.caption(f"æœ€åæ›´æ–°æ—¶é—´: {timestamp}")
                
                # è½¬æ¢ä¸ºDataFrame
                df = pd.DataFrame(data.get("data", []))
                
                if not df.empty:
                    # æ˜¾ç¤ºå¸‚åœºæ¦‚å†µ
                    st.subheader("ğŸ“ˆ å¸‚åœºæ¦‚å†µ")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("æ€»äº¤æ˜“å¯¹æ•°é‡", len(df))
                    
                    with col2:
                        increased = len(df[df['change'] > 0])
                        st.metric("æŒä»“å¢åŠ æ•°é‡", increased)
                    
                    with col3:
                        decreased = len(df[df['change'] < 0])
                        st.metric("æŒä»“å‡å°‘æ•°é‡", decreased)
                    
                    # æ˜¾ç¤ºæŒä»“å˜åŒ–æœ€å¤§çš„äº¤æ˜“å¯¹
                    st.subheader("ğŸ“Š æŒä»“å˜åŒ–åˆ†æ")
                    
                    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ğŸŸ¢ æŒä»“å¢åŠ æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹")
                        top_increase = df[df['change'] > 0].sort_values('change_percentage', ascending=False).head(10)
                        if not top_increase.empty:
                            st.dataframe(top_increase[['symbol', 'current_oi', 'change', 'change_percentage']], hide_index=True)
                            
                    
                        else:
                            st.write("æš‚æ— æ•°æ®")
                    
                    with col2:
                        st.subheader("ğŸ”´ æŒä»“å‡å°‘æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹")
                        top_decrease = df[df['change'] < 0].sort_values('change_percentage', ascending=True).head(10)
                        if not top_decrease.empty:
                            st.dataframe(top_decrease[['symbol', 'current_oi', 'change', 'change_percentage']], hide_index=True)
                            
                            
                        else:
                            st.write("æš‚æ— æ•°æ®")
                    
                    # æ˜¾ç¤ºAIåˆ†æç»“æœ
                    st.subheader("ğŸ¤– AI åˆ†æ")
                    with st.spinner("æ­£åœ¨ç”ŸæˆAIåˆ†æ..."):
                        analysis = get_ai_analysis(df)
                        st.markdown(analysis)
                else:
                    st.warning("æ•°æ®ä¸ºç©ºï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æ•°æ®")
        else:
            st.warning("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®è·å–æ•°æ®")
            
            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿è¡Œä¸€æ¬¡ä»»åŠ¡
            if st.button("è·å–æ•°æ®"):
                with st.spinner("æ­£åœ¨è·å–æ•°æ®..."):
                    analyzer = BinanceFuturesAnalyzer()
                    df = analyzer.analyze_positions()
                    
                    # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
                    with open("binance_perps_analysis.json", "w") as f:
                        json.dump({
                            "data": df.to_dict('records'),
                            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        }, f, indent=4, ensure_ascii=False)
                    
                    st.success("æ•°æ®å·²è·å–!")
                    st.rerun()
    
    except Exception as e:
        st.error(f"è¯»å–æ•°æ®æ—¶å‡ºé”™: {e}")
    
    # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨åˆ·æ–°ï¼Œè®¾ç½®å®šæ—¶åˆ·æ–°
    if auto_refresh:
        st.caption("é¡µé¢å°†åœ¨5åˆ†é’Ÿåè‡ªåŠ¨åˆ·æ–°")
        time.sleep(300)  # ç­‰å¾…5åˆ†é’Ÿ
        st.rerun()

if __name__ == "__main__":
    main()
